1. What is overfitting? Hige variance
  Overfitting is a concept in machine learning and statistics, and it can be explained in plain language like this:
    Imagine you're trying to teach a robot to recognize cats in pictures. You show it hundreds of cat pictures so it can learn what a cat looks like. If you teach the robot too well on just these pictures, it might get really good at recognizing these specific cats, but not so good at recognizing new cats it hasn't seen before. This is because it has learned all the tiny, specific details of the cats in the training pictures, including things that don't really matter when identifying a cat, like a specific background or a cat's pose.
  Overfitting is like this. It happens when a machine learning model learns the details and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means the model is too tailored to the training data, and doesn't perform well when it sees data it hasn't seen before. In simpler terms, the model is great at remembering but not so great at generalizing.

2. What is underfitting? Hige bias
  Underfitting is another concept in machine learning and statistics, and it's like the opposite of overfitting. Here's a simple way to understand it:
    Let's go back to the robot learning to recognize cats. This time, imagine you don't show the robot enough cat pictures, or the pictures are too vague and don't cover the variety of cats out there. Maybe you only show it a few pictures of black cats sitting in the same position. Now, when the robot sees a new cat picture, especially if it's not a black cat or in a different pose, it might not recognize it as a cat. This is because it hasn't learned enough about what makes a cat a cat; it only knows about a very narrow example of cats.
  Underfitting happens when a machine learning model is too simple and hasnâ€™t learned enough from the training data. This lack of learning means the model doesn't perform well even on the training data and, as a result, also performs poorly on new, unseen data. It's like the model is underprepared; it doesn't have a broad enough understanding of what it's supposed to learn.
